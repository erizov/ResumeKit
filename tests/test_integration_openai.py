"""
OpenAI integration tests (optional, skipped if API key not set).

These tests verify real OpenAI API integration when enabled.
They are skipped if OPENAI_API_KEY is not configured.
"""

import os

import pytest
from fastapi.testclient import TestClient

from app.db import Base, engine
from app.main import app


@pytest.fixture(autouse=True, scope="module")
def _ensure_tables():
    """
    Ensure database tables exist before running tests.
    """
    Base.metadata.create_all(bind=engine)
    yield


client = TestClient(app)

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
RESUMEKIT_USE_OPENAI = os.getenv("RESUMEKIT_USE_OPENAI", "").lower() in {
    "1",
    "true",
    "yes",
}

skip_if_no_openai = pytest.mark.skipif(
    not OPENAI_API_KEY or not RESUMEKIT_USE_OPENAI,
    reason="OPENAI_API_KEY and RESUMEKIT_USE_OPENAI not set",
)


@skip_if_no_openai
def test_openai_tailoring_enabled() -> None:
    """
    Verify that OpenAI tailoring produces different output than stub.

    This test only runs if OPENAI_API_KEY and RESUMEKIT_USE_OPENAI are set.
    """
    payload = {
        "job_description": (
            "Senior Backend Developer position. "
            "Required: Python, FastAPI, PostgreSQL, Docker."
        ),
        "resume_text": (
            "Experienced backend developer with Python and FastAPI. "
            "Worked with PostgreSQL databases."
        ),
        "languages": "en",
        "targets": "backend",
        "aggressiveness": 2,
    }

    response = client.post("/api/recommend", data=payload)
    assert response.status_code == 200

    data = response.json()
    resumes = data["resumes"]
    assert len(resumes) == 1

    resume = resumes[0]
    assert resume["language"] == "en"
    assert resume["target"] == "backend"

    # OpenAI-generated content should be different from stub
    # (stub would include "[TAILORED RESUME - lang=..." header)
    assert "[TAILORED RESUME - lang=" not in resume["content"]

    # Should contain relevant keywords from JD
    assert "Python" in resume["content"] or "FastAPI" in resume["content"]

    # Notes should indicate OpenAI was used
    assert resume.get("notes") is not None
    assert "OpenAI" in resume["notes"]


@skip_if_no_openai
def test_openai_multiple_languages() -> None:
    """
    Verify OpenAI can generate resumes in multiple languages.
    """
    payload = {
        "job_description": "Backend developer role.",
        "resume_text": "Backend developer with Python experience.",
        "languages": "en,ru",
        "targets": "backend",
    }

    response = client.post("/api/recommend", data=payload)
    assert response.status_code == 200

    data = response.json()
    resumes = data["resumes"]
    assert len(resumes) == 2

    languages = {r["language"] for r in resumes}
    assert languages == {"en", "ru"}

    # Both should be generated by OpenAI (not stub)
    for resume in resumes:
        assert "[TAILORED RESUME - lang=" not in resume["content"]


@skip_if_no_openai
def test_openai_different_targets() -> None:
    """
    Verify OpenAI generates different content for different targets.
    """
    payload = {
        "job_description": "Developer role.",
        "resume_text": "Developer with Python and React experience.",
        "languages": "en",
        "targets": "backend,fullstack",
    }

    response = client.post("/api/recommend", data=payload)
    assert response.status_code == 200

    data = response.json()
    resumes = data["resumes"]
    assert len(resumes) == 2

    targets = {r["target"] for r in resumes}
    assert targets == {"backend", "fullstack"}

    # Content should differ between targets
    backend_content = next(r["content"] for r in resumes if r["target"] == "backend")
    fullstack_content = next(
        r["content"] for r in resumes if r["target"] == "fullstack"
    )

    # They should be different (not identical)
    assert backend_content != fullstack_content


@skip_if_no_openai
def test_openai_aggressiveness_levels() -> None:
    """
    Verify different aggressiveness levels produce different outputs.
    """
    base_payload = {
        "job_description": "Backend developer role.",
        "resume_text": "Developer with Python experience.",
        "languages": "en",
        "targets": "backend",
    }

    # Generate with aggressiveness 1
    payload1 = {**base_payload, "aggressiveness": 1}
    response1 = client.post("/api/recommend", data=payload1)
    assert response1.status_code == 200
    content1 = response1.json()["resumes"][0]["content"]

    # Generate with aggressiveness 3
    payload3 = {**base_payload, "aggressiveness": 3}
    response3 = client.post("/api/recommend", data=payload3)
    assert response3.status_code == 200
    content3 = response3.json()["resumes"][0]["content"]

    # Content should differ (more aggressive should be more rewritten)
    # Note: This is a heuristic test; exact differences depend on LLM
    assert content1 != content3


def test_stub_mode_when_openai_disabled() -> None:
    """
    Verify stub mode works when OpenAI is disabled.

    This test always runs to ensure stub mode functions correctly.
    """
    # Temporarily disable OpenAI if it was enabled
    original_use_openai = os.getenv("RESUMEKIT_USE_OPENAI")
    os.environ.pop("RESUMEKIT_USE_OPENAI", None)

    try:
        payload = {
            "job_description": "Backend role.",
            "resume_text": "Backend developer.",
            "languages": "en",
            "targets": "backend",
        }

        response = client.post("/api/recommend", data=payload)
        assert response.status_code == 200

        data = response.json()
        resume = data["resumes"][0]

        # Stub mode should include the stub header
        assert "[TAILORED RESUME - lang=" in resume["content"]
    finally:
        # Restore original setting
        if original_use_openai:
            os.environ["RESUMEKIT_USE_OPENAI"] = original_use_openai

